{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3005f79",
   "metadata": {},
   "source": [
    "## Setup and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab4be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n",
      "None\n",
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
      "\n",
      "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
      "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
      "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
      "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
      "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
      "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
      "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
      "\n",
      "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
      "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
      "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
      "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
      "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
      "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
      "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
      "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
      "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "sample_submission = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "\n",
    "# Initial exploration\n",
    "print(train_df.head())\n",
    "print(train_df.info())\n",
    "print(train_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing = train_df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62da79",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d618e479",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [['RL' 'RL' 'RL' ... 'RL' 'RL' 'RL']\n ['Pave' 'Pave' 'Pave' ... 'Pave' 'Pave' 'Pave']\n [nan nan nan ... nan nan nan]\n ...\n [nan nan nan ... 'Shed' nan nan]\n ['WD' 'WD' 'WD' ... 'WD' 'WD' 'WD']\n ['Normal' 'Normal' 'Normal' ... 'Normal' 'Normal' 'Normal']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fill missing values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df\u001b[38;5;241m.\u001b[39mfillna(train_df\u001b[38;5;241m.\u001b[39mmedian(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m test_df\u001b[38;5;241m.\u001b[39mfillna(test_df\u001b[38;5;241m.\u001b[39mmedian(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Encode categorical variables\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11679\u001b[0m, in \u001b[0;36mDataFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11671\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m  11672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  11673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11677\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11678\u001b[0m ):\n\u001b[0;32m> 11679\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmedian(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m  11680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11681\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:12424\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12419\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12422\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12423\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  12425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  12426\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:12370\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12366\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12368\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  12371\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  12372\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11535\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11531\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  11533\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11534\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11535\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[1;32m  11536\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  11537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1501\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1499\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1501\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[1;32m   1502\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1504\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11454\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11452\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[1;32m  11453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 11454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert [['RL' 'RL' 'RL' ... 'RL' 'RL' 'RL']\n ['Pave' 'Pave' 'Pave' ... 'Pave' 'Pave' 'Pave']\n [nan nan nan ... nan nan nan]\n ...\n [nan nan nan ... 'Shed' nan nan]\n ['WD' 'WD' 'WD' ... 'WD' 'WD' 'WD']\n ['Normal' 'Normal' 'Normal' ... 'Normal' 'Normal' 'Normal']] to numeric"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "train_df.fillna(train_df.median(), inplace=True)\n",
    "test_df.fillna(test_df.median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in train_df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "train_df[train_df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(train_df.select_dtypes(include=[np.number]))\n",
    "test_df[test_df.select_dtypes(include=[np.number]).columns] = scaler.transform(test_df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Feature selection (example using correlation)\n",
    "corr_matrix = train_df.corr()\n",
    "high_corr_features = corr_matrix.index[abs(corr_matrix[\"SalePrice\"]) > 0.5]\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(train_df[high_corr_features].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "# Use selected features\n",
    "selected_features = high_corr_features.drop(\"SalePrice\")\n",
    "X = train_df[selected_features]\n",
    "y = train_df['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ce0cf",
   "metadata": {},
   "source": [
    "## Handle Missing Values and Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b95170d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     11\u001b[0m train_df[numeric_features] \u001b[38;5;241m=\u001b[39m train_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(train_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m---> 12\u001b[0m test_df[numeric_features] \u001b[38;5;241m=\u001b[39m test_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(test_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fill missing values for categorical features with the mode\u001b[39;00m\n\u001b[1;32m     15\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mobject\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SalePrice'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925bf7f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     11\u001b[0m train_df[numeric_features] \u001b[38;5;241m=\u001b[39m train_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(train_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m---> 12\u001b[0m test_df[numeric_features] \u001b[38;5;241m=\u001b[39m test_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(test_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fill missing values for categorical features with the mode\u001b[39;00m\n\u001b[1;32m     15\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mobject\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SalePrice'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c4661e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     11\u001b[0m train_df[numeric_features] \u001b[38;5;241m=\u001b[39m train_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(train_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m---> 12\u001b[0m test_df[numeric_features] \u001b[38;5;241m=\u001b[39m test_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(test_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fill missing values for categorical features with the mode\u001b[39;00m\n\u001b[1;32m     15\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mobject\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SalePrice'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Ensure all columns are encoded correctly\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2ce399",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     11\u001b[0m train_df[numeric_features] \u001b[38;5;241m=\u001b[39m train_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(train_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m---> 12\u001b[0m test_df[numeric_features] \u001b[38;5;241m=\u001b[39m test_df[numeric_features]\u001b[38;5;241m.\u001b[39mfillna(test_df[numeric_features]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fill missing values for categorical features with the mode\u001b[39;00m\n\u001b[1;32m     15\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mobject\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SalePrice'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Ensure all columns are encoded correctly\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab442ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0   1          60         3         65.0     8450       1      0         3   \n",
      "1   2          20         3         80.0     9600       1      0         3   \n",
      "2   3          60         3         68.0    11250       1      0         0   \n",
      "3   4          70         3         60.0     9550       1      0         0   \n",
      "4   5          60         3         84.0    14260       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...            0         0       2      2   \n",
      "1            3          0  ...            0         0       2      2   \n",
      "2            3          0  ...            0         0       2      2   \n",
      "3            3          0  ...            0         0       2      2   \n",
      "4            3          0  ...            0         0       2      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       2    2008         8              4  \n",
      "1            2        0       5    2007         8              4  \n",
      "2            2        0       9    2008         8              4  \n",
      "3            2        0       2    2006         8              0  \n",
      "4            2        0      12    2008         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "     Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0  1461          20         2         80.0    11622       1      0         3   \n",
      "1  1462          20         3         81.0    14267       1      0         0   \n",
      "2  1463          60         3         74.0    13830       1      0         0   \n",
      "3  1464          60         3         78.0     9978       1      0         0   \n",
      "4  1465         120         3         43.0     5005       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...          120         0       0      2   \n",
      "1            3          0  ...            0         0       0      2   \n",
      "2            3          0  ...            0         0       0      2   \n",
      "3            3          0  ...            0         0       0      2   \n",
      "4            1          0  ...          144         0       0      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       6    2010         8              4  \n",
      "1            0    12500       6    2010         8              4  \n",
      "2            2        0       3    2010         8              4  \n",
      "3            2        0       6    2010         8              4  \n",
      "4            2        0       1    2010         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Separate target variable from training data\n",
    "y = train_df['SalePrice']\n",
    "train_df = train_df.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Ensure all columns are encoded correctly\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3afd73",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d6ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "test_df[numeric_features] = scaler.transform(test_df[numeric_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f203fc",
   "metadata": {},
   "source": [
    "## Feature Selection and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6afcd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SalePrice back to the train_df for correlation computation\n",
    "train_df['SalePrice'] = y\n",
    "\n",
    "# Selecting high correlation features\n",
    "corr_matrix = train_df.corr()\n",
    "high_corr_features = corr_matrix.index[abs(corr_matrix[\"SalePrice\"]) > 0.5]\n",
    "\n",
    "# Prepare training data\n",
    "X = train_df[high_corr_features].drop(\"SalePrice\", axis=1)\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce829c",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327b0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 37195.83368735172\n",
      "Cross-validated RMSE: 36575.27639489314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(lr, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Cross-validated RMSE: {-cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8a3c4",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ad504d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index.drop() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_features \u001b[38;5;241m=\u001b[39m test_df[high_corr_features\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m      3\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(test_features)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create submission file\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index.drop() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "test_features = test_df[high_corr_features.drop(\"SalePrice\", axis=0)]\n",
    "test_predictions = lr.predict(test_features)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397e2f4",
   "metadata": {},
   "source": [
    "## Step 1: Handle Missing Values and Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726f56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0   1          60         3         65.0     8450       1      0         3   \n",
      "1   2          20         3         80.0     9600       1      0         3   \n",
      "2   3          60         3         68.0    11250       1      0         0   \n",
      "3   4          70         3         60.0     9550       1      0         0   \n",
      "4   5          60         3         84.0    14260       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...            0         0       2      2   \n",
      "1            3          0  ...            0         0       2      2   \n",
      "2            3          0  ...            0         0       2      2   \n",
      "3            3          0  ...            0         0       2      2   \n",
      "4            3          0  ...            0         0       2      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       2    2008         8              4  \n",
      "1            2        0       5    2007         8              4  \n",
      "2            2        0       9    2008         8              4  \n",
      "3            2        0       2    2006         8              0  \n",
      "4            2        0      12    2008         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "     Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0  1461          20         2         80.0    11622       1      0         3   \n",
      "1  1462          20         3         81.0    14267       1      0         0   \n",
      "2  1463          60         3         74.0    13830       1      0         0   \n",
      "3  1464          60         3         78.0     9978       1      0         0   \n",
      "4  1465         120         3         43.0     5005       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...          120         0       0      2   \n",
      "1            3          0  ...            0         0       0      2   \n",
      "2            3          0  ...            0         0       0      2   \n",
      "3            3          0  ...            0         0       0      2   \n",
      "4            1          0  ...          144         0       0      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       6    2010         8              4  \n",
      "1            0    12500       6    2010         8              4  \n",
      "2            2        0       3    2010         8              4  \n",
      "3            2        0       6    2010         8              4  \n",
      "4            2        0       1    2010         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# Separate target variable from training data\n",
    "y = train_df['SalePrice']\n",
    "train_df = train_df.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Ensure all columns are encoded correctly\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9c16e",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e454da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "test_df[numeric_features] = scaler.transform(test_df[numeric_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3dc3a",
   "metadata": {},
   "source": [
    "## Feature Selection and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bf8b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SalePrice back to the train_df for correlation computation\n",
    "train_df['SalePrice'] = y\n",
    "\n",
    "# Selecting high correlation features\n",
    "corr_matrix = train_df.corr()\n",
    "high_corr_features = corr_matrix.index[abs(corr_matrix[\"SalePrice\"]) > 0.5]\n",
    "\n",
    "# Prepare training data\n",
    "X = train_df[high_corr_features.drop(\"SalePrice\")]\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0c008",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9c24752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 37195.83368735172\n",
      "Cross-validated RMSE: 36575.27639489314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(lr, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Cross-validated RMSE: {-cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f1624",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ef0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_features = test_df[high_corr_features.drop(\"SalePrice\")]\n",
    "test_predictions = lr.predict(test_features)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2df59",
   "metadata": {},
   "source": [
    "this failed; told it to match the format of sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de55193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0   1          60         3         65.0     8450       1      0         3   \n",
      "1   2          20         3         80.0     9600       1      0         3   \n",
      "2   3          60         3         68.0    11250       1      0         0   \n",
      "3   4          70         3         60.0     9550       1      0         0   \n",
      "4   5          60         3         84.0    14260       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...            0         0       2      2   \n",
      "1            3          0  ...            0         0       2      2   \n",
      "2            3          0  ...            0         0       2      2   \n",
      "3            3          0  ...            0         0       2      2   \n",
      "4            3          0  ...            0         0       2      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       2    2008         8              4  \n",
      "1            2        0       5    2007         8              4  \n",
      "2            2        0       9    2008         8              4  \n",
      "3            2        0       2    2006         8              0  \n",
      "4            2        0      12    2008         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "     Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0  1461          20         2         80.0    11622       1      0         3   \n",
      "1  1462          20         3         81.0    14267       1      0         0   \n",
      "2  1463          60         3         74.0    13830       1      0         0   \n",
      "3  1464          60         3         78.0     9978       1      0         0   \n",
      "4  1465         120         3         43.0     5005       1      0         0   \n",
      "\n",
      "   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n",
      "0            3          0  ...          120         0       0      2   \n",
      "1            3          0  ...            0         0       0      2   \n",
      "2            3          0  ...            0         0       0      2   \n",
      "3            3          0  ...            0         0       0      2   \n",
      "4            1          0  ...          144         0       0      2   \n",
      "\n",
      "   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            2        0       6    2010         8              4  \n",
      "1            0    12500       6    2010         8              4  \n",
      "2            2        0       3    2010         8              4  \n",
      "3            2        0       6    2010         8              4  \n",
      "4            2        0       1    2010         8              4  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "sample_submission = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "\n",
    "# Separate target variable from training data\n",
    "y = train_df['SalePrice']\n",
    "train_df = train_df.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Fill missing values for numeric features with the median\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(test_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values for categorical features with the mode\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(test_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[column] = le.fit_transform(train_df[column])\n",
    "    test_df[column] = le.transform(test_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Ensure all columns are encoded correctly\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2beaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "test_df[numeric_features] = scaler.transform(test_df[numeric_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a3a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SalePrice back to the train_df for correlation computation\n",
    "train_df['SalePrice'] = y\n",
    "\n",
    "# Selecting high correlation features\n",
    "corr_matrix = train_df.corr()\n",
    "high_corr_features = corr_matrix.index[abs(corr_matrix[\"SalePrice\"]) > 0.5]\n",
    "\n",
    "# Prepare training data\n",
    "X = train_df[high_corr_features.drop(\"SalePrice\")]\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fbae636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 37195.83368735172\n",
      "Cross-validated RMSE: 36575.27639489314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(lr, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Cross-validated RMSE: {-cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "398f6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_features = test_df[high_corr_features.drop(\"SalePrice\")]\n",
    "test_predictions = lr.predict(test_features)\n",
    "\n",
    "# Create submission file matching the format of sample_submission.csv\n",
    "submission = pd.DataFrame({'Id': sample_submission['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f27c9",
   "metadata": {},
   "source": [
    "got a 0.18 number 3871 see if we can improve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2640494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/train.csv')\n",
    "test_df = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/test.csv')\n",
    "sample_submission = pd.read_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "\n",
    "# Separate target variable from training data\n",
    "y = train_df['SalePrice']\n",
    "train_df = train_df.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# List of numerical and categorical features\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = train_df.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Preprocessing pipeline for numerical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Preprocessing pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Apply the transformations\n",
    "X_train = preprocessor.fit_transform(train_df)\n",
    "X_test = preprocessor.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0ed52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for ridge: {'alpha': 10.0}\n",
      "Best CV score for ridge: 31111.85506302248\n",
      "Training lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117679256561.79984, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51713889291.65961, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63030160083.57837, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70953124805.89368, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58699542956.621, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19657138691.19165, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9902532703.833008, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10178874518.03418, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105320747452.3292, tolerance: 920791133.4609987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for lasso: {'alpha': 0.01}\n",
      "Best CV score for lasso: 34465.373672339054\n",
      "Training elasticnet...\n",
      "Best params for elasticnet: {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "Best CV score for elasticnet: 31045.49724883262\n",
      "Training gbr...\n",
      "Best params for gbr: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for gbr: 26277.917296814092\n",
      "Training rf...\n",
      "Best params for rf: {'max_depth': 20, 'n_estimators': 200}\n",
      "Best CV score for rf: 29806.78523122042\n",
      "Training xgb...\n",
      "Best params for xgb: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for xgb: 26981.828436640866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: gbr\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define models and their hyperparameters for GridSearchCV\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elasticnet': ElasticNet(),\n",
    "    'gbr': GradientBoostingRegressor(),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'xgb': XGBRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ridge': {'alpha': [0.1, 1.0, 10.0]},\n",
    "    'lasso': {'alpha': [0.01, 0.1, 1.0]},\n",
    "    'elasticnet': {'alpha': [0.1, 1.0], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'gbr': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]},\n",
    "    'rf': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'xgb': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best params for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score for {name}: {-grid_search.best_score_}\")\n",
    "\n",
    "# Select the best model based on CV score\n",
    "best_model_name = min(best_models, key=lambda k: -cross_val_score(best_models[k], X_train, y, cv=5, scoring='neg_root_mean_squared_error').mean())\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train, y)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Create submission file matching the format of sample_submission.csv\n",
    "submission = pd.DataFrame({'Id': sample_submission['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eb90252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for ridge: {'alpha': 10.0}\n",
      "Best CV score for ridge: 31111.85506302248\n",
      "Training lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117679256561.79984, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70953124805.89368, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51713889291.65961, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63030160083.57837, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58699542956.621, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9902532703.833008, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10178874518.03418, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19657138691.19165, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105320747452.3292, tolerance: 920791133.4609987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for lasso: {'alpha': 0.01}\n",
      "Best CV score for lasso: 34465.373672339054\n",
      "Training elasticnet...\n",
      "Best params for elasticnet: {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "Best CV score for elasticnet: 31045.49724883262\n",
      "Training gbr...\n",
      "Best params for gbr: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for gbr: 26013.877054701792\n",
      "Training rf...\n",
      "Best params for rf: {'max_depth': 20, 'n_estimators': 100}\n",
      "Best CV score for rf: 29853.01832757257\n",
      "Training xgb...\n",
      "Best params for xgb: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for xgb: 26981.828436640866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: gbr\n",
      "Hyperparameters of the best model: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define models and their hyperparameters for GridSearchCV\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elasticnet': ElasticNet(),\n",
    "    'gbr': GradientBoostingRegressor(),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'xgb': XGBRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ridge': {'alpha': [0.1, 1.0, 10.0]},\n",
    "    'lasso': {'alpha': [0.01, 0.1, 1.0]},\n",
    "    'elasticnet': {'alpha': [0.1, 1.0], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'gbr': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]},\n",
    "    'rf': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'xgb': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best params for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score for {name}: {-grid_search.best_score_}\")\n",
    "\n",
    "# Select the best model based on CV score\n",
    "best_model_name = min(best_models, key=lambda k: -cross_val_score(best_models[k], X_train, y, cv=5, scoring='neg_root_mean_squared_error').mean())\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Print the best model's hyperparameters\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Hyperparameters of the best model: {best_model.get_params()}\")\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train, y)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Create submission file matching the format of sample_submission.csv\n",
    "submission = pd.DataFrame({'Id': sample_submission['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36eb3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for ridge: {'alpha': 10.0}\n",
      "Best CV score for ridge: 31111.85506302248\n",
      "Training lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117679256561.79984, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51713889291.65961, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63030160083.57837, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70953124805.89368, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58699542956.621, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9902532703.833008, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10178874518.03418, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19657138691.19165, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105320747452.3292, tolerance: 920791133.4609987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for lasso: {'alpha': 0.01}\n",
      "Best CV score for lasso: 34465.373672339054\n",
      "Training elasticnet...\n",
      "Best params for elasticnet: {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "Best CV score for elasticnet: 31045.49724883262\n",
      "Training gbr...\n",
      "Best params for gbr: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for gbr: 25883.561544934433\n",
      "Training rf...\n",
      "Best params for rf: {'max_depth': None, 'n_estimators': 200}\n",
      "Best CV score for rf: 29696.145224493044\n",
      "Training xgb...\n",
      "Best params for xgb: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Best CV score for xgb: 26981.828436640866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101954032534.39963, tolerance: 759214014.2531193\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104518385704.79805, tolerance: 728773513.0259368\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71706623569.40408, tolerance: 699031751.5199751\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80073388411.82462, tolerance: 770619031.1834052\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/Users/john/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:589: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117453682752.80618, tolerance: 724930391.3116125\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: gbr\n",
      "Hyperparameters of the best model: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define models and their hyperparameters for GridSearchCV\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elasticnet': ElasticNet(),\n",
    "    'gbr': GradientBoostingRegressor(),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'xgb': XGBRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ridge': {'alpha': [0.1, 1.0, 10.0]},\n",
    "    'lasso': {'alpha': [0.01, 0.1, 1.0]},\n",
    "    'elasticnet': {'alpha': [0.1, 1.0], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'gbr': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]},\n",
    "    'rf': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'xgb': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best params for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score for {name}: {-grid_search.best_score_}\")\n",
    "\n",
    "# Select the best model based on CV score\n",
    "best_model_name = min(best_models, key=lambda k: -cross_val_score(best_models[k], X_train, y, cv=5, scoring='neg_root_mean_squared_error').mean())\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Print the best model's hyperparameters\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Hyperparameters of the best model: {best_model.get_params()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96db4bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created using the best model: gbr with hyperparameters: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train, y)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Create submission file matching the format of sample_submission.csv\n",
    "submission = pd.DataFrame({'Id': sample_submission['Id'], 'SalePrice': test_predictions})\n",
    "submission.to_csv('/Users/john/Downloads/house-prices-advanced-regression-techniques/submission.csv', index=False)\n",
    "\n",
    "print(f\"Submission file created using the best model: {best_model_name} with hyperparameters: {best_model.get_params()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f16698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
